# ğŸ¦™ğŸŒŸ ChatBot-vits-llama-lora-Haruhi

 > åŸºäº `Llama-Chinese` loraå¾®è°ƒ å’Œ `GPT-SoVITS`çš„å®æ—¶è¯­éŸ³èŠå¤©Botï¼

> **Update**:
> 
> ä¸Šä¼ äº†åˆå§‹ç‰ˆæœ¬ï¼Œ å…¶ä¸­Haruhiçš„æ•°æ®é›†è¯­æ–™æ¥è‡ªï¼š**[Chat-Haruhi-Suzumiya](https://github.com/LC1332/Chat-Haruhi-Suzumiya?tab=readme-ov-file)** 
> 
> è¯­éŸ³ç”ŸæˆAPIæ¥è‡ªï¼š**[GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)** 
>
>å¯¹è¯æ¨¡å‹æ¥è‡ªï¼š**[Llama-Chinese](https://github.com/LlamaFamily/Llama-Chinese)** è¿›è¡Œloraå¾®è°ƒåå¾—åˆ°
>

## åŠŸèƒ½

**[ç‚¹å‡»æ­¤å¤„è·³è½¬Bilibiliæ¼”ç¤ºè§†é¢‘](https://huggingface.co/spaces/zetavg/LLaMA-LoRA-UI-Demo)** 
> ä¸è™šæ‹Ÿè§’è‰²è¿›è¡Œå®æ—¶çš„äº¤æµï¼Œå¹¶å®æ—¶ç”Ÿæˆè¯­éŸ³å›å¤ï¼

## å¦‚ä½•å¼€å§‹

é¦–å…ˆéœ€è¦å‰ç½®é…ç½®Llama-Chineseä¸GPT-Sovits:

* **[å¯åŠ¨GPT-Sovitsçš„API](https://github.com/RVC-Boss/GPT-SoVITS/blob/main/README.md)**: ç¯å¢ƒå®‰è£…å®Œæˆåï¼Œéœ€è¦è¿è¡Œ[api.py](https://github.com/RVC-Boss/GPT-SoVITS/blob/main/api.py)å¯åŠ¨é¡¹ç›®çš„APIä»¥ç”Ÿæˆè¯­éŸ³
* **[å…‹éš†Llama-Chineseè‡³æœ¬åœ°](#https://github.com/LlamaFamily/Llama-Chinese)**: è¿è¡Œpip install -r requirements.txt å®‰è£…ä¾èµ–



### ä¾èµ–å®‰è£…

<details>
  <summary>åœ¨condaä¸­åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ</summary>

  ```bash
  conda create -y python=3.10.8 -n llama-bot-chat
  conda activate llama-bot-chat
  ```
</details>

```bash
pip install -r requirements.txt
```
### è¿è¡Œwebui

`python webui.py`.

### å‘½ä»¤è¡Œä½¿ç”¨
` python main.py --query ä»Šå¤©æ‰“ç®—å»åƒæ±‰å ¡ --base_model Llama3-Chinese-8B-Instruct --lora_model Llama-Chinese-main/Llama-Chinese-main/save_folder --is_transform True `

## æ¨¡å‹é‡åŒ–
1. å¯ä»¥ä½¿ç”¨AutoGPTQåœ¨è¿›è¡Œloraå¾®è°ƒå‰è¿›è¡Œæ¨¡å‹é‡åŒ–ï¼Œå…·ä½“å¯ä»¥å‚è€ƒ[ä½¿ç”¨-peft-å¾®è°ƒé‡åŒ–åçš„æ¨¡å‹](https://huggingface.co/blog/zh/gptq-integration#--%E4%BD%BF%E7%94%A8-peft-%E5%BE%AE%E8%B0%83%E9%87%8F%E5%8C%96%E5%90%8E%E7%9A%84%E6%A8%A1%E5%9E%8B--)
2. ä½¿ç”¨TensorRT-LLM[TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM.git)è¿›è¡Œæ¨ç†åŠ é€Ÿï¼Œæœ¬é¡¹ç›®åŸºäºllamaï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥åœ¨[é“¾æ¥](https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/llama)ä¸­å‚è€ƒä¼˜åŒ–ä»£ç `å¯èƒ½ä¼šå‡ºç°é™æ™ºç°è±¡`ï¼Œç¤ºä¾‹æ­¥éª¤(å•GPU)ï¼š

```bash
python convert_checkpoint.py   --model_dir /home/chwu/MODELS/Llama3-Chinese-8B-Instruct   --output_dir ./tllm_checkpoint_1gpu   --dtype float16   --tp_size 1 # Llamaæƒé‡è½¬æ¢ä¸ºtensorRT-llmæ ¼å¼
```
```bash
trtllm-build   --checkpoint_dir ./tllm_checkpoint_1gpu   --output_dir /tmp/new_lora_13b/trt_engines/fp16/1-gpu/   --gemm_plugin auto   --lora_plugin auto   --max_batch_size 1   --max_input_len 512   --max_seq_len 562   --lora_dir /path/to/your/lora/weight  --world_size 1 # ç”ŸæˆtensorRT-llm engine
```
```bash
mpirun --allow-run-as-root -n 1 python ../run_wrapper.py   --engine_dir "/tmp/new_lora_13b/trt_engines/fp16/1-gpu/"   --max_output_len 50   --tokenizer_dir /path/to/your/lora/weight   --input_text "ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼"   --lora_task_uids 0   --no_add_special_tokens   --use_py_session # è¿›è¡Œæ¨ç†
```
```bash
# ä¹Ÿå¯ä»¥é€šè¿‡è¿è¡Œæ‰“åŒ…æ–‡ä»¶è¿›è¡Œæ¨ç†
python ChatBot-vits-llama-lora-Haruhi/inference-speed/GPU/TensorRT-LLM_example/run_lora.py
```
## loraæƒé‡ä»¥åŠé¢„è®­ç»ƒæƒé‡ä¸‹è½½
> **[loraæƒé‡ä¸‹è½½](https://pan.baidu.com/s/1MQWZ45OweIcomv5knu6OyQ)**:05wi
> **[Llama3-Chinese-8B-Instruct æƒé‡ä¸‹è½½](https://huggingface.co/FlagAlpha/Llama3-Chinese-8B-Instruct)**

## Acknowledgements

* https://github.com/RVC-Boss/GPT-SoVITS
* https://github.com/LlamaFamily/Llama-Chinese
* ...
